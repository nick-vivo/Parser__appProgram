{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZGpxB-YXhH_"
      },
      "source": [
        "# Прикладное программирование\n",
        "\n",
        "## Лабораторная работа 1. Автоматизированный сбор данных. Работа со строками.\n",
        "\n",
        "# Общие требования к лабораторным работам\n",
        "\n",
        "1. Лабораторная работа выполняется в виде отдельного python-скрипта. *Дополнительный плюс можно получить усложнив себе задание и сопроводив скрипт python-ноутбуком с решением.*\n",
        "1. Каждая лабораторная работа должна быть загружена в отдельный git-репозиторий.\n",
        "1. Взаимодействие с репозиторием должно производиться посредством работы с IDE, а не через сайт.\n",
        "1. Репозитории с одним коммитом к проверке не принимаются.\n",
        "1. Сообщения коммитов должны быть осмысленными и отражать процесс выполнения задания.\n",
        "1. Код должен соответствовать требованиям соглашения PEP8.\n",
        "\n",
        "Невыполнение любого из перечисленных требований может быть причиной неуспешной сдачи лабораторной работы и повлечь переделывание (в некоторых случаях с дополнительными заданиями).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QneJD4iOORr"
      },
      "source": [
        "# Web scraping\n",
        "Веб-скрейпинг (или скрепинг, или скрапинг← англ. web scraping) — это технология получения веб-данных путем извлечения их со страниц веб-ресурсов. Веб-скрейпинг может быть сделан вручную пользователем компьютера, однако термин обычно относится к автоматизированным процессам, реализованным с помощью кода, который выполняет GET-запросы на целевой сайт.\n",
        "\n",
        "[Некоторая вспомогательная информация (не является руководством к действию)](https://tproger.ru/translations/skraping-sajta-s-pomoshhju-python-gajd-dlja-novichkov/)\n",
        "\n",
        "Для парсинга html разрешено использовать **BeautifulSoup**.\n",
        "\n",
        "## Получение html кода веб-страницы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjhU9rX-1_ch"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import requests\n",
        "\n",
        "URL = \"https://yandex.ru/\"\n",
        "html_page = requests.get(URL, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "# html_page.text - хранит html код веб-страницы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNO8hvr-_S7p"
      },
      "source": [
        "Для работы с загруженными изображениями (не обязательно с расширением, характерным для изображения!) вам могут потребоваться следующие инструкции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2  # импорт библиотеки, предназначенной для работы с изображениями\n",
        "\n",
        "image = cv2.imread(path_to_file)  # прочтение изображения из файла, path_to_file - путь до файла-изображения\n",
        "cv2.imwrite(path_to_save_image, image)  # сохранение изображения по заданному пути, например, path_to_folder/image_name.jpg\n",
        "\n",
        "print(image.shape)  # распечатать размер прочитанного изображения\n",
        "\n",
        "# инструкции для просмотра изображения\n",
        "cv2.imshow(window_name, image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smd1hFtQXEY1"
      },
      "source": [
        "\n",
        "С использованием сервиса **livelib** соберите по 1000 рецензий для каждого количества звёзд для различных книг. То есть суммарный объём датасета 5000 рецензий. Сохраните каждый отзыв в отдельный текстовый файл, где на первой строке будет указано название книги.\n",
        "\n",
        "**Не допускается**:\n",
        "\n",
        "1.   Создание папок вручную. В коде должен быть отражен процесс создания папок и перемещения/загрузки в них файлов.\n",
        "2.   Дублирование данных для класса.\n",
        "\n",
        "**Примечания**\n",
        "\n",
        "Именовать файлы необходимо порядковым номером (от 0 до 999).\n",
        "\n",
        "Для дальнейшего удобства необходимо дополнять имя файла ведующими нулями (например, 0000, 0001, ..., 0999). Для этого необходимо использовать один из методов класса **str**.\n",
        "\n",
        "Каждую рецензию сохраните в отдельный текстовый файл в соответствующую подпапку папки **dataset**. (Пути должны быть dataset/0/0001.txt, dataset/1/0001.txt, и т. д. по количеству звёзд)\n",
        "\n",
        "Обратите внимание, на то что страницы с отзывами необходимо обрабатывать в цикле.\n",
        "\n",
        "Пример ссылки для получения отзывов: https://www.livelib.ru/reviews/~2#reviews\n",
        "\n",
        "Вариант подразумевает два уровня сложности:\n",
        "\n",
        "1.   Для первого уровня сложности достаточно сохранить начало отзыва, показываемое на странице.\n",
        "2.   Для второго уровня сложности необходимо сохранить отзыв полностью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBFRGROMcJNn"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "image_1 = cv2.imread(\"1.jpg\")\n",
        "image_2 = cv2.imread(\"2.jpg\")\n",
        "\n",
        "def cmp(image_1: cv2.Mat, image_2: cv2.Mat) -> bool:\n",
        "  return image_1 == image_2"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
